"""
3D Landmarks Visualizer

This module provides functionality to visualize sign language landmarks in 3D space
from video_landmarks.json files generated by the processing pipeline.

Usage:
    from visualizer_3d import visualize_landmarks_3d
    visualize_landmarks_3d("path/to/video_landmarks.json")
"""

import json
import numpy as np
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
from matplotlib.animation import FuncAnimation
from pathlib import Path
from typing import Dict, List, Optional, Tuple
import argparse
from collections import defaultdict, deque


class LandmarksVisualizer3D:
    """3D visualizer for sign language landmarks"""

    def __init__(self, json_path: str, frame_rate: float = 10.0, track_hands: bool = False):
        """
        Initialize the 3D visualizer

        Args:
            json_path: Path to video_landmarks.json file
            frame_rate: Animation frame rate (frames per second)
            track_hands: Whether to enable hand path tracking
        """
        self.json_path = Path(json_path)
        self.frame_rate = frame_rate
        self.track_hands = track_hands
        self.data = None
        self.frames_data = None
        self.metadata = None
        self.current_frame = 0

        # Initialize hand path tracker if enabled
        self.hand_tracker = None

        # Color scheme for different landmark types
        self.colors = {
            'hands': {'left_hand': 'red', 'right_hand': 'blue'},
            'face': 'yellow',
            'pose': 'green'
        }

        # Load data
        self._load_data()

        # Initialize hand tracking after data is loaded
        if track_hands:
            self.hand_tracker = HandPathTracker()
            self.hand_tracker.precompute_paths_from_json(self.frames_data)

            # Print path statistics
            stats = self.hand_tracker.get_path_statistics()
            print("Hand Path Statistics:")
            print(f"  Left hand: {stats['left_hand']['total_points']} points, "
                  f"distance: {stats['left_hand']['total_distance']:.3f}, "
                  f"avg speed: {stats['left_hand']['avg_speed']:.3f}")
            print(f"  Right hand: {stats['right_hand']['total_points']} points, "
                  f"distance: {stats['right_hand']['total_distance']:.3f}, "
                  f"avg speed: {stats['right_hand']['avg_speed']:.3f}")

    def _load_data(self):
        """Load landmarks data from JSON file"""
        if not self.json_path.exists():
            raise FileNotFoundError(f"JSON file not found: {self.json_path}")

        try:
            with open(self.json_path, 'r') as f:
                self.data = json.load(f)

            self.metadata = self.data.get('metadata', {})
            self.frames_data = self.data.get('frames', {})

            if not self.frames_data:
                raise ValueError("No frames data found in JSON file")

            print(f"Loaded data for {len(self.frames_data)} frames")
            print(f"Source: {self.metadata.get('input_source', 'Unknown')}")
            print(f"FPS: {self.metadata.get('fps', 'Unknown')}")

        except Exception as e:
            raise Exception(f"Error loading JSON file: {e}")

    def _extract_landmarks_for_frame(self, frame_key: str) -> Dict:
        """Extract 3D coordinates for a specific frame"""
        frame_data = self.frames_data.get(frame_key, {})
        landmarks_3d = {
            'hands': {'left_hand': [], 'right_hand': []},
            'face': [],
            'pose': []
        }

        # Extract hand landmarks
        hands_data = frame_data.get('hands', {})
        for hand_type in ['left_hand', 'right_hand']:
            hand_info = hands_data.get(hand_type, {})
            if isinstance(hand_info, dict) and 'landmarks' in hand_info:
                # New format with confidence
                hand_landmarks = hand_info['landmarks']
            elif isinstance(hand_info, list):
                # Old format - direct list
                hand_landmarks = hand_info
            else:
                hand_landmarks = []

            if hand_landmarks:
                points = np.array([[lm['x'], lm['y'], lm['z']] for lm in hand_landmarks])
                landmarks_3d['hands'][hand_type] = points

        # Extract face landmarks (using all landmarks)
        face_data = frame_data.get('face', {})
        if 'all_landmarks' in face_data and face_data['all_landmarks']:
            # Use a subset of face landmarks for better visualization
            face_landmarks = face_data['all_landmarks']
            # Take every 10th landmark to reduce clutter
            sampled_landmarks = face_landmarks[::2]
            points = np.array([[lm['x'], lm['y'], lm['z']] for lm in sampled_landmarks])
            landmarks_3d['face'] = points

        # Extract pose landmarks
        pose_data = frame_data.get('pose', {})
        if pose_data:
            # Extract key pose landmarks
            key_pose_points = [
                'NOSE', 'LEFT_EYE', 'RIGHT_EYE', 'LEFT_EAR', 'RIGHT_EAR',
                'LEFT_SHOULDER', 'RIGHT_SHOULDER', 'LEFT_ELBOW', 'RIGHT_ELBOW',
                'LEFT_WRIST', 'RIGHT_WRIST', 'LEFT_HIP', 'RIGHT_HIP',
                'LEFT_KNEE', 'RIGHT_KNEE', 'LEFT_ANKLE', 'RIGHT_ANKLE'
            ]

            pose_points = []
            for landmark_name in key_pose_points:
                if landmark_name in pose_data:
                    lm = pose_data[landmark_name]
                    # Check visibility if available
                    visibility = lm.get('visibility', 1.0)
                    if visibility > 0.5:  # Only include visible landmarks
                        pose_points.append([lm['x'], lm['y'], lm['z']])

            if pose_points:
                landmarks_3d['pose'] = np.array(pose_points)

        return landmarks_3d

    def _setup_3d_plot(self):
        """Set up the 3D matplotlib plot"""
        self.fig = plt.figure(figsize=(12, 9))
        self.ax = self.fig.add_subplot(111, projection='3d')

        # Set labels and title
        self.ax.set_xlabel('X')
        self.ax.set_ylabel('Y')
        self.ax.set_zlabel('Z')
        self.ax.set_title(f'3D Landmarks Visualization\nSource: {self.metadata.get("input_source", "Unknown")}')

        # Set axis limits (normalized coordinates are 0-1)
        self.ax.set_xlim(0, 1)
        self.ax.set_ylim(0, 1)
        self.ax.set_zlim(-0.5, 0.5)  # Z coordinates are typically smaller

        # Invert Y axis to match image coordinates
        self.ax.invert_yaxis()

        return self.ax

    def _draw_frame(self, frame_num: int):
        """Draw landmarks for a specific frame"""
        self.ax.clear()

        # Set up plot again
        self.ax.set_xlabel('X')
        self.ax.set_ylabel('Y')
        self.ax.set_zlabel('Z')
        self.ax.set_xlim(0, 1)
        self.ax.set_ylim(0, 1)
        self.ax.set_zlim(-0.5, 0.5)
        self.ax.invert_yaxis()

        # Get frame key
        frame_keys = sorted(self.frames_data.keys(), key=int)
        if frame_num >= len(frame_keys):
            frame_num = len(frame_keys) - 1

        frame_key = frame_keys[frame_num]
        current_frame_number = int(frame_key)
        landmarks = self._extract_landmarks_for_frame(frame_key)

        # Draw hand landmarks
        for hand_type, points in landmarks['hands'].items():
            if len(points) > 0:
                color = self.colors['hands'][hand_type]
                self.ax.scatter(points[:, 0], points[:, 1], points[:, 2],
                                c=color, s=30, alpha=0.8, label=f'{hand_type.replace("_", " ").title()}')

                # Draw hand connections (simplified)
                self._draw_hand_connections(points, color)

        # Draw face landmarks
        if len(landmarks['face']) > 0:
            self.ax.scatter(landmarks['face'][:, 0], landmarks['face'][:, 1], landmarks['face'][:, 2],
                            c=self.colors['face'], s=10, alpha=0.6, label='Face')

        # Draw pose landmarks
        if len(landmarks['pose']) > 0:
            self.ax.scatter(landmarks['pose'][:, 0], landmarks['pose'][:, 1], landmarks['pose'][:, 2],
                            c=self.colors['pose'], s=50, alpha=0.8, label='Pose')

            # Draw pose connections
            self._draw_pose_connections(landmarks['pose'])

        # Draw hand paths if tracking is enabled
        if self.hand_tracker:
            # For animations, show progressive path up to current frame
            # For static, show full path
            show_full_path = not hasattr(self, '_is_animating') or not self._is_animating
            self.hand_tracker.draw_paths_3d(self.ax, current_frame_number, show_full_path)

        # Update title with frame info
        frame_timestamp = float(frame_key) / self.metadata.get('fps', 30)
        tracking_status = " (Hand Tracking ON)" if self.track_hands else ""
        self.ax.set_title(f'Frame {frame_key} (t={frame_timestamp:.2f}s){tracking_status}\n'
                          f'Source: {self.metadata.get("input_source", "Unknown")}')

        # Add legend
        self.ax.legend(loc='upper left', bbox_to_anchor=(0, 1))

        return self.ax

    def _draw_hand_connections(self, points: np.ndarray, color: str):
        """Draw connections between hand landmarks"""
        if len(points) != 21:  # MediaPipe hand has 21 landmarks
            return

        # Define hand connections (simplified version)
        connections = [
            # Thumb
            (0, 1), (1, 2), (2, 3), (3, 4),
            # Index finger
            (0, 5), (5, 6), (6, 7), (7, 8),
            # Middle finger
            (0, 9), (9, 10), (10, 11), (11, 12),
            # Ring finger
            (0, 13), (13, 14), (14, 15), (15, 16),
            # Pinky
            (0, 17), (17, 18), (18, 19), (19, 20),
            # Palm connections
            (5, 9), (9, 13), (13, 17)
        ]

        for start_idx, end_idx in connections:
            start_point = points[start_idx]
            end_point = points[end_idx]
            self.ax.plot([start_point[0], end_point[0]],
                         [start_point[1], end_point[1]],
                         [start_point[2], end_point[2]],
                         color=color, alpha=0.5, linewidth=1)

    def _draw_pose_connections(self, points: np.ndarray):
        """Draw connections between pose landmarks"""
        # This is simplified - would need to map the actual pose landmark indices
        # For now, just connect some basic points
        if len(points) >= 4:
            # Connect shoulders to create basic pose structure
            color = self.colors['pose']
            for i in range(len(points) - 1):
                if i % 2 == 0 and i + 1 < len(points):  # Connect pairs
                    self.ax.plot([points[i][0], points[i + 1][0]],
                                 [points[i][1], points[i + 1][1]],
                                 [points[i][2], points[i + 1][2]],
                                 color=color, alpha=0.3, linewidth=1)

    def visualize_static(self, frame_number: Optional[int] = None):
        """Display a static 3D visualization of landmarks for a specific frame"""
        self._setup_3d_plot()

        # Mark as not animating for full path display
        self._is_animating = False

        if frame_number is None:
            frame_number = 0

        self._draw_frame(frame_number)

        # Add instructions with hand tracking info
        instruction_text = 'Use mouse to rotate view. Close window to exit.'
        if self.track_hands:
            instruction_text += '\nShowing complete hand movement paths.'

        plt.figtext(0.02, 0.02, instruction_text, fontsize=10, style='italic')

        plt.tight_layout()
        plt.show()

    def visualize_animated(self, interval: float = 100):
        """Display an animated 3D visualization of landmarks across all frames"""
        self._setup_3d_plot()

        # Set animation flag for progressive path tracking
        self._is_animating = True

        frame_keys = sorted(self.frames_data.keys(), key=int)
        total_frames = len(frame_keys)

        def animate(frame):
            return self._draw_frame(frame)

        # Create animation
        self.anim = FuncAnimation(self.fig, animate, frames=total_frames,
                                  interval=interval, blit=False, repeat=True)

        # Add instructions
        instruction_text = 'Animation playing. Use mouse to rotate view. Close window to exit.'
        if self.track_hands:
            instruction_text += '\nHand paths build progressively as animation plays.'

        plt.figtext(0.02, 0.02, instruction_text, fontsize=10, style='italic')

        plt.tight_layout()
        plt.show()

        return self.anim

    def save_animation(self, output_path: str, fps: float = 10):
        """Save the 3D animation as a video file"""
        self._setup_3d_plot()

        frame_keys = sorted(self.frames_data.keys(), key=int)
        total_frames = len(frame_keys)

        def animate(frame):
            return self._draw_frame(frame)

        # Create animation
        anim = FuncAnimation(self.fig, animate, frames=total_frames,
                             interval=1000 / fps, blit=False, repeat=False)

        # Save animation
        print(f"Saving 3D animation to {output_path}...")
        anim.save(output_path, writer='pillow', fps=fps)
        print(f"Animation saved successfully!")

        plt.close()

    def analyze_hand_paths(self):
        """Analyze and print detailed hand path information"""
        if not self.hand_tracker:
            print("Hand tracking is not enabled. Use track_hands=True to enable analysis.")
            return

        stats = self.hand_tracker.get_path_statistics()

        print("\n" + "=" * 50)
        print("HAND PATH ANALYSIS")
        print("=" * 50)

        print(f"\nVideo Information:")
        print(f"  Source: {self.metadata.get('input_source', 'Unknown')}")
        print(f"  FPS: {self.metadata.get('fps', 'Unknown')}")
        print(f"  Total frames: {len(self.frames_data)}")

        print(f"\nLeft Hand Movement:")
        print(f"  Detected in {stats['left_hand']['total_points']} frames")
        if stats['left_hand']['total_points'] > 0:
            print(f"  Total distance traveled: {stats['left_hand']['total_distance']:.3f} units")
            print(f"  Average speed: {stats['left_hand']['avg_speed']:.3f} units/second")
            print(f"  Maximum speed: {stats['left_hand']['max_speed']:.3f} units/second")

        print(f"\nRight Hand Movement:")
        print(f"  Detected in {stats['right_hand']['total_points']} frames")
        if stats['right_hand']['total_points'] > 0:
            print(f"  Total distance traveled: {stats['right_hand']['total_distance']:.3f} units")
            print(f"  Average speed: {stats['right_hand']['avg_speed']:.3f} units/second")
            print(f"  Maximum speed: {stats['right_hand']['max_speed']:.3f} units/second")

        # Detect periods of high activity
        print(f"\nMovement Analysis:")
        if self.hand_tracker.full_left_hand_path or self.hand_tracker.full_right_hand_path:
            print("  Use the 3D visualization to see detailed movement patterns.")
            print("  Green markers = Start positions")
            print("  Red/Blue markers = Current/End positions")
            print("  Path opacity increases toward the end of movement")

        print("=" * 50)


class HandPathTracker:
    """Tracks and visualizes hand movement paths from JSON data"""

    def __init__(self, max_path_length: int = 50):
        """
        Initialize hand path tracker

        Args:
            max_path_length: Maximum number of points to keep in path history
        """
        self.max_path_length = max_path_length
        self.left_hand_path = deque(maxlen=max_path_length)
        self.right_hand_path = deque(maxlen=max_path_length)

        # Store full paths for analysis
        self.full_left_hand_path = []
        self.full_right_hand_path = []

        # Path colors (slightly transparent)
        self.path_colors = {
            'left_hand': (1.0, 0.5, 0.5, 0.7),  # Light red with alpha
            'right_hand': (0.5, 0.5, 1.0, 0.7)  # Light blue with alpha
        }

        # Wrist landmark index (MediaPipe hand landmark 0 is wrist)
        self.wrist_index = 0

    def precompute_paths_from_json(self, frames_data: dict):
        """Precompute all hand paths from JSON data"""
        print("Precomputing hand paths from JSON data...")

        # Sort frame keys numerically
        sorted_frame_keys = sorted(frames_data.keys(), key=int)

        for frame_key in sorted_frame_keys:
            frame_data = frames_data[frame_key]
            hands_data = frame_data.get('hands', {})

            # Process left hand
            left_hand = hands_data.get('left_hand', [])
            if left_hand:
                # Handle both old and new JSON formats
                if isinstance(left_hand, dict) and 'landmarks' in left_hand:
                    landmarks = left_hand['landmarks']
                else:
                    landmarks = left_hand

                if landmarks and len(landmarks) > self.wrist_index:
                    wrist_point = landmarks[self.wrist_index]
                    point = [wrist_point['x'], wrist_point['y'], wrist_point['z']]
                    self.full_left_hand_path.append({
                        'frame': int(frame_key),
                        'point': point,
                        'timestamp': frame_data.get('timestamp', int(frame_key) / 30.0)
                    })

            # Process right hand
            right_hand = hands_data.get('right_hand', [])
            if right_hand:
                # Handle both old and new JSON formats
                if isinstance(right_hand, dict) and 'landmarks' in right_hand:
                    landmarks = right_hand['landmarks']
                else:
                    landmarks = right_hand

                if landmarks and len(landmarks) > self.wrist_index:
                    wrist_point = landmarks[self.wrist_index]
                    point = [wrist_point['x'], wrist_point['y'], wrist_point['z']]
                    self.full_right_hand_path.append({
                        'frame': int(frame_key),
                        'point': point,
                        'timestamp': frame_data.get('timestamp', int(frame_key) / 30.0)
                    })

        print(
            f"Computed paths: Left hand {len(self.full_left_hand_path)} points, Right hand {len(self.full_right_hand_path)} points")

    def update_paths_for_frame(self, target_frame: int):
        """Update visible paths up to the target frame"""
        self.left_hand_path.clear()
        self.right_hand_path.clear()

        # Add left hand points up to target frame
        for path_point in self.full_left_hand_path:
            if path_point['frame'] <= target_frame:
                self.left_hand_path.append(path_point['point'])
            else:
                break

        # Add right hand points up to target frame
        for path_point in self.full_right_hand_path:
            if path_point['frame'] <= target_frame:
                self.right_hand_path.append(path_point['point'])
            else:
                break

    def get_path_for_frame_range(self, start_frame: int, end_frame: int, hand_type: str):
        """Get path points for a specific frame range"""
        if hand_type == 'left_hand':
            path_data = self.full_left_hand_path
        elif hand_type == 'right_hand':
            path_data = self.full_right_hand_path
        else:
            return []

        return [point['point'] for point in path_data
                if start_frame <= point['frame'] <= end_frame]

    def draw_paths_3d(self, ax, current_frame: int = None, show_full_path: bool = False):
        """Draw hand paths on 3D plot"""
        if show_full_path or current_frame is None:
            # Draw complete paths
            left_points = [p['point'] for p in self.full_left_hand_path]
            right_points = [p['point'] for p in self.full_right_hand_path]
        else:
            # Draw paths up to current frame
            left_points = [p['point'] for p in self.full_left_hand_path if p['frame'] <= current_frame]
            right_points = [p['point'] for p in self.full_right_hand_path if p['frame'] <= current_frame]

        # Draw left hand path
        if len(left_points) > 1:
            path_array = np.array(left_points)

            # Draw main path line
            ax.plot(path_array[:, 0], path_array[:, 1], path_array[:, 2],
                    color=self.path_colors['left_hand'][:3],
                    alpha=self.path_colors['left_hand'][3],
                    linewidth=3, label='Left Hand Path')

            # Add gradient effect by plotting segments with varying alpha
            num_segments = min(20, len(path_array) - 1)
            segment_size = max(1, len(path_array) // num_segments)

            for i in range(0, len(path_array) - segment_size, segment_size):
                end_idx = min(i + segment_size, len(path_array))
                alpha = (i / len(path_array)) * 0.3 + 0.4  # Alpha from 0.4 to 0.7
                ax.plot(path_array[i:end_idx, 0], path_array[i:end_idx, 1], path_array[i:end_idx, 2],
                        color=self.path_colors['left_hand'][:3], alpha=alpha, linewidth=2)

            # Mark start and end points
            if len(path_array) > 0:
                # Start point (green)
                ax.scatter([path_array[0, 0]], [path_array[0, 1]], [path_array[0, 2]],
                           c='green', s=100, marker='o', alpha=0.8, label='Left Start')
                # End point (red)
                ax.scatter([path_array[-1, 0]], [path_array[-1, 1]], [path_array[-1, 2]],
                           c='red', s=100, marker='s', alpha=0.8, label='Left Current')

        # Draw right hand path
        if len(right_points) > 1:
            path_array = np.array(right_points)

            # Draw main path line
            ax.plot(path_array[:, 0], path_array[:, 1], path_array[:, 2],
                    color=self.path_colors['right_hand'][:3],
                    alpha=self.path_colors['right_hand'][3],
                    linewidth=3, label='Right Hand Path')

            # Add gradient effect
            num_segments = min(20, len(path_array) - 1)
            segment_size = max(1, len(path_array) // num_segments)

            for i in range(0, len(path_array) - segment_size, segment_size):
                end_idx = min(i + segment_size, len(path_array))
                alpha = (i / len(path_array)) * 0.3 + 0.4  # Alpha from 0.4 to 0.7
                ax.plot(path_array[i:end_idx, 0], path_array[i:end_idx, 1], path_array[i:end_idx, 2],
                        color=self.path_colors['right_hand'][:3], alpha=alpha, linewidth=2)

            # Mark start and end points
            if len(path_array) > 0:
                # Start point (green)
                ax.scatter([path_array[0, 0]], [path_array[0, 1]], [path_array[0, 2]],
                           c='green', s=100, marker='o', alpha=0.8, label='Right Start')
                # End point (blue)
                ax.scatter([path_array[-1, 0]], [path_array[-1, 1]], [path_array[-1, 2]],
                           c='blue', s=100, marker='s', alpha=0.8, label='Right Current')

    def get_path_statistics(self):
        """Get statistics about hand movements"""
        stats = {
            'left_hand': {
                'total_points': len(self.full_left_hand_path),
                'total_distance': 0.0,
                'avg_speed': 0.0,
                'max_speed': 0.0
            },
            'right_hand': {
                'total_points': len(self.full_right_hand_path),
                'total_distance': 0.0,
                'avg_speed': 0.0,
                'max_speed': 0.0
            }
        }

        # Calculate distances and speeds for left hand
        if len(self.full_left_hand_path) > 1:
            distances = []
            speeds = []
            for i in range(1, len(self.full_left_hand_path)):
                p1 = np.array(self.full_left_hand_path[i - 1]['point'])
                p2 = np.array(self.full_left_hand_path[i]['point'])
                distance = np.linalg.norm(p2 - p1)
                distances.append(distance)

                time_diff = self.full_left_hand_path[i]['timestamp'] - self.full_left_hand_path[i - 1]['timestamp']
                if time_diff > 0:
                    speed = distance / time_diff
                    speeds.append(speed)

            stats['left_hand']['total_distance'] = sum(distances)
            if speeds:
                stats['left_hand']['avg_speed'] = np.mean(speeds)
                stats['left_hand']['max_speed'] = np.max(speeds)

        # Calculate distances and speeds for right hand
        if len(self.full_right_hand_path) > 1:
            distances = []
            speeds = []
            for i in range(1, len(self.full_right_hand_path)):
                p1 = np.array(self.full_right_hand_path[i - 1]['point'])
                p2 = np.array(self.full_right_hand_path[i]['point'])
                distance = np.linalg.norm(p2 - p1)
                distances.append(distance)

                time_diff = self.full_right_hand_path[i]['timestamp'] - self.full_right_hand_path[i - 1]['timestamp']
                if time_diff > 0:
                    speed = distance / time_diff
                    speeds.append(speed)

            stats['right_hand']['total_distance'] = sum(distances)
            if speeds:
                stats['right_hand']['avg_speed'] = np.mean(speeds)
                stats['right_hand']['max_speed'] = np.max(speeds)

        return stats


def visualize_landmarks_3d(json_path: str, mode: str = 'static', frame_number: Optional[int] = None,
                           save_path: Optional[str] = None, track_hands: bool = False):
    """
    Visualize landmarks from video_landmarks.json in 3D space

    Args:
        json_path: Path to the video_landmarks.json file
        mode: 'static' for single frame, 'animated' for animation
        frame_number: Specific frame to show (for static mode), None for first frame
        save_path: Path to save animation (optional, for animated mode)
        track_hands: Whether to enable hand path tracking visualization
    """
    try:
        visualizer = LandmarksVisualizer3D(json_path, track_hands=track_hands)

        # Show analysis if hand tracking is enabled
        if track_hands:
            visualizer.analyze_hand_paths()

        if mode == 'static':
            visualizer.visualize_static(frame_number)
        elif mode == 'animated':
            if save_path:
                visualizer.save_animation(save_path)
            else:
                visualizer.visualize_animated()
        else:
            raise ValueError("Mode must be 'static' or 'animated'")

    except Exception as e:
        print(f"Error in visualization: {e}")
        raise


def generate_2d_path_overlay_from_json(json_path: str, output_video_path: str = None):
    """
    Generate a 2D video with hand path overlays from JSON data
    This works independently of the original video processing
    """
    import cv2

    # Load JSON data
    with open(json_path, 'r') as f:
        data = json.load(f)

    frames_data = data.get('frames', {})
    metadata = data.get('metadata', {})

    if not frames_data:
        print("No frame data found in JSON")
        return

    # Get video properties from metadata
    fps = metadata.get('fps', 30)
    resolution = metadata.get('resolution', '640x480')
    width, height = map(int, resolution.split('x'))

    # Set up output video
    if output_video_path is None:
        output_video_path = Path(json_path).parent / "hand_paths_overlay.mp4"

    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    out = cv2.VideoWriter(str(output_video_path), fourcc, fps, (width, height))

    # Initialize hand tracker
    hand_tracker = HandPathTracker()
    hand_tracker.precompute_paths_from_json(frames_data)

    # Generate frames
    frame_keys = sorted(frames_data.keys(), key=int)

    for frame_key in frame_keys:
        # Create blank frame
        frame = np.zeros((height, width, 3), dtype=np.uint8)

        current_frame_num = int(frame_key)

        # Get paths up to current frame
        left_points = [(int(p['point'][0] * width), int(p['point'][1] * height))
                       for p in hand_tracker.full_left_hand_path
                       if p['frame'] <= current_frame_num]

        right_points = [(int(p['point'][0] * width), int(p['point'][1] * height))
                        for p in hand_tracker.full_right_hand_path
                        if p['frame'] <= current_frame_num]

        # Draw paths
        if len(left_points) > 1:
            for i in range(1, len(left_points)):
                alpha = i / len(left_points)
                thickness = max(1, int(5 * alpha))
                cv2.line(frame, left_points[i - 1], left_points[i], (0, 100, 255), thickness)

        if len(right_points) > 1:
            for i in range(1, len(right_points)):
                alpha = i / len(right_points)
                thickness = max(1, int(5 * alpha))
                cv2.line(frame, right_points[i - 1], right_points[i], (255, 100, 0), thickness)

        # Add current hand positions
        current_frame_data = frames_data[frame_key]
        hands_data = current_frame_data.get('hands', {})

        for hand_type, color in [('left_hand', (0, 255, 255)), ('right_hand', (255, 255, 0))]:
            hand_data = hands_data.get(hand_type, [])
            if hand_data:
                if isinstance(hand_data, dict) and 'landmarks' in hand_data:
                    landmarks = hand_data['landmarks']
                else:
                    landmarks = hand_data

                if landmarks:
                    wrist = landmarks[0]
                    x, y = int(wrist['x'] * width), int(wrist['y'] * height)
                    cv2.circle(frame, (x, y), 8, color, -1)
                    cv2.putText(frame, hand_type.replace('_', ' ').title(),
                                (x + 10, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)

        # Add frame info
        cv2.putText(frame, f"Frame: {frame_key}", (10, 30),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 1)

        out.write(frame)

    out.release()
    print(f"Hand path overlay video saved to: {output_video_path}")

def main():
    """Command line interface for 3D visualization"""
    parser = argparse.ArgumentParser(description='Visualize sign language landmarks in 3D')
    parser.add_argument('json_path', help='Path to video_landmarks.json file')
    parser.add_argument('--mode', choices=['static', 'animated'], default='static',
                        help='Visualization mode (default: static)')
    parser.add_argument('--frame', type=int, default=0,
                        help='Frame number to display (for static mode, default: 0)')
    parser.add_argument('--save', type=str,
                        help='Save animation to file (for animated mode)')
    parser.add_argument('--track-hands', action='store_true',
                        help='Enable hand path visualization and analysis')

    args = parser.parse_args()

    print(f"Loading landmarks from: {args.json_path}")
    print(f"Mode: {args.mode}")
    print(f"Hand tracking: {'ON' if args.track_hands else 'OFF'}")

    if args.mode == 'static':
        print(f"Displaying frame: {args.frame}")

    visualize_landmarks_3d(args.json_path, args.mode, args.frame, args.save, args.track_hands)

if __name__ == "__main__":
    main()